{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e359610-32ca-416c-85b9-68e30b154821",
   "metadata": {},
   "outputs": [],
   "source": [
    "from RNARepLearn.datasets import CombinedRfamDataset\n",
    "from RNARepLearn.utils import train_val_test_loaders, add_backbone, generate_edges,reconstruct_bpp\n",
    "from RNARepLearn.train import MaskedTraining\n",
    "from RNARepLearn.models import Encoder_Decoder_Model, Seq_Struc_GNN, CombinedGNN\n",
    "from RNARepLearn.layers import Sep_Seq_Struc_Layer\n",
    "from RNARepLearn.modules import CNN_Seq, RPINetEncoder, TE_Decoder, AttentionDecoder\n",
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GCNConv, TransformerConv\n",
    "from torch_geometric.transforms import AddLaplacianEigenvectorPE\n",
    "from torch_geometric.utils import to_dense_batch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "166c9d3f-3fd4-4528-9509-eb3e14e46796",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from RNARepLearn.datasets import CombinedRfamDataset\n",
    "from RNARepLearn.utils import train_val_test_loaders, add_backbone\n",
    "\n",
    "ds = CombinedRfamDataset(\"/lustre/groups/crna01/workspace/nicolas_msc/RNARepLearn/rfam/data/raw/processed/release-14.8\", None ,\"All_300\")# , add_LPE=True, add_backbone=True, transform=AddLaplacianEigenvectorPE(16, attr_name=None)\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf583d82-bef0-4e31-a176-0c68d59bea24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\t695\n",
      "Test:\t694216\n",
      "Validation:\t697\n"
     ]
    }
   ],
   "source": [
    "train, val, test = train_val_test_loaders(ds, 0.001, 0.001, 0.998, 64, num_workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62961ccc-5bd4-4199-8997-aa4c8643e4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn = Seq_Struc_GNN(4, 128, 6, GCNConv)\n",
    "#gnn = CombinedGNN(20,128, 4, TransformerConv, edge_dim=2).double()\n",
    "\n",
    "#tconv = TransformerConv(20, 128, edge_dim=2)\n",
    "#gnn = RPINetEncoder(4,64,3,9)\n",
    "#decoder = TE_Decoder(batch_size,128)\n",
    "decoder = AttentionDecoder(128, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d499375-214d-4cee-94c2-583c90e4648c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Encoder_Decoder_Model(gnn, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "37918c95-0110-4cf8-b5d9-b5064339a2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "570a561b-5041-4c5e-9dfe-b439d6a9caee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pred_nucs, pred_bpp = model(batch)\n",
    "\n",
    "pred_nucs = pred_nucs\n",
    "pred_bpp = pred_bpp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "96b1b54d-bb1a-4e9a-9127-cca9748f62f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_bpp = torch.tensor(reconstruct_bpp(batch.edge_index, batch.edge_weight, (len(batch.x),len(batch.x))))\n",
    "true_mat = true_bpp!=0\n",
    "pred_mat = pred_bpp!=0\n",
    "all_mat = torch.ones(len(true_mat)**2, dtype=torch.bool).reshape(len(true_mat),len(true_mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d80bdffc-6854-49b0-8df5-aac4dd4a4340",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = torch.sum(torch.logical_and(true_mat, pred_mat)) #intersection true and pred\n",
    "FP = torch.sum(torch.logical_and(torch.logical_and(all_mat, ~true_mat), pred_mat)) #setdiff all_edges / true_edges (e.g. all_edges and !ture_edges)\n",
    "FN = torch.sum(torch.logical_and(torch.logical_and(all_mat, ~pred_mat), true_mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0fae938b-ee01-4515-86d2-b7db5457dbb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(402997)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "84cd9361-4dfb-40a0-832c-b85d462463d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_edges = generate_edges(torch.ones(len(pred_nucs),len(pred_nucs))).contiguous().numpy()\n",
    "pred_edges = generate_edges(pred_bpp).contiguous().numpy()\n",
    "true_edges = batch.edge_index.T.contiguous().numpy()\n",
    "\n",
    "dtype={'names':['f{}'.format(i) for i in range(pred_edges.shape[1])],\n",
    "       'formats':pred_edges.shape[1] * [pred_edges.dtype]}\n",
    "\n",
    "true_pos = len(np.intersect1d(pred_edges.view(dtype), true_edges.view(dtype), assume_unique=True))\n",
    "\n",
    "false_pos = len(np.intersect1d(np.setdiff1d(all_edges.view(dtype), true_edges.view(dtype), assume_unique=True), pred_edges.view(dtype), assume_unique=True))\n",
    "\n",
    "false_neg = len(np.intersect1d(true_edges,np.setdiff1d(all_edges,pred_edges, assume_unique=True),assume_unique=True))\n",
    "\n",
    "precision = true_pos/(true_pos+false_pos)\n",
    "\n",
    "recall = true_pos/(true_pos+false_neg)\n",
    "\n",
    "f1 = 2 * (precision*recall)/(precision+recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cdcfd2b8-04c5-4c90-aa34-94d07c0d9053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(396664, 2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_pos.view(pred_edges.dtype).reshape(-1, pred_edges.shape[1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f130d0de-fa58-490a-9661-a2f22946bc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuple_func(x):\n",
    "    return tuple(x)\n",
    "func = np.vectorize(tuple_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2210ad0-d8fb-4400-b326-711b91388295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111601800,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.in1d(all_edges, pred_edges).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7046c709-5c49-4fb3-b9c6-f96e3c6e0ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55800900, 2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "683013b7-30bc-4309-8602-80dd53f020e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_edges = [tuple(i) for i in all_edges]\n",
    "pred_edges = [tuple()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b621d95-274c-4f26-9c4e-2c3fcdc30a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "713f8481-b058-4d90-a059-a287c4091c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1,4],[2,5],[4,1]])\n",
    "B = np.array([[1,4],[3,6],[7,8], [4,1]])\n",
    "\n",
    "nrows, ncols = A.shape\n",
    "dtype={'names':['f{}'.format(i) for i in range(ncols)],\n",
    "       'formats':ncols * [A.dtype]}\n",
    "\n",
    "C = np.intersect1d(A.view(dtype), B.view(dtype))\n",
    "\n",
    "# This last bit is optional if you're okay with \"C\" being a structured array...\n",
    "C = C.view(A.dtype).reshape(-1, ncols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "525ea85d-a0a4-42a0-b688-624d0bfce4b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45819361, 2)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_edges.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f27dea1-ac87-41e4-81c7-f00c1aedcf0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new SummaryWriter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-06 19:55:57.079212: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/RNARepLearn/lib/python3.10/site-packages/tensorboard/compat/__init__.py:42\u001b[0m, in \u001b[0;36mtf\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m notf  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'notf' from 'tensorboard.compat' (/home/icb/vnicolas.goedert/miniconda3/envs/RNARepLearn/lib/python3.10/site-packages/tensorboard/compat/__init__.py)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m training \u001b[38;5;241m=\u001b[39m \u001b[43mMaskedTraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_out\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/RNARepLearn/lib/python3.10/site-packages/gin/config.py:1582\u001b[0m, in \u001b[0;36m_make_gin_wrapper.<locals>.gin_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1579\u001b[0m new_kwargs\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n\u001b[1;32m   1581\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1582\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1583\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m   1584\u001b[0m   err_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/RNARepLearn/lib/python3.10/site-packages/RNARepLearn/train.py:32\u001b[0m, in \u001b[0;36mMaskedTraining.__init__\u001b[0;34m(self, model, n_epochs, masked_percentage, writer, lr, weight_decay, mask, mask_seq, mask_struc, validation_steps, node_loss_weight, edge_loss_weight, early_stopping_patience, add_bb, print_out)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, n_epochs, masked_percentage, writer, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.002\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5e-4\u001b[39m , mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, mask_seq\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, mask_struc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, validation_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, node_loss_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, edge_loss_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, early_stopping_patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, add_bb\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, print_out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmasked_percentage \u001b[38;5;241m=\u001b[39m masked_percentage\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask \u001b[38;5;241m=\u001b[39m mask\n",
      "File \u001b[0;32m~/miniconda3/envs/RNARepLearn/lib/python3.10/site-packages/RNARepLearn/train.py:24\u001b[0m, in \u001b[0;36mTraining.__init__\u001b[0;34m(self, model, n_epochs, writer, lr, weight_decay)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating new SummaryWriter\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m \u001b[43mSummaryWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(model))\n",
      "File \u001b[0;32m~/miniconda3/envs/RNARepLearn/lib/python3.10/site-packages/torch/utils/tensorboard/writer.py:247\u001b[0m, in \u001b[0;36mSummaryWriter.__init__\u001b[0;34m(self, log_dir, comment, purge_step, max_queue, flush_secs, filename_suffix)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;66;03m# Initialize the file writers, but they can be cleared out on close\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;66;03m# and recreated later as needed.\u001b[39;00m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_writer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_writers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 247\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_file_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# Create default bins for histograms, see generate_testdata.py in tensorflow/tensorboard\u001b[39;00m\n\u001b[1;32m    250\u001b[0m v \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-12\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/RNARepLearn/lib/python3.10/site-packages/torch/utils/tensorboard/writer.py:277\u001b[0m, in \u001b[0;36mSummaryWriter._get_file_writer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the default FileWriter instance. Recreates it if closed.\"\"\"\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_writers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_writer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 277\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_writer \u001b[38;5;241m=\u001b[39m \u001b[43mFileWriter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_queue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflush_secs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilename_suffix\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_writers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_writer\u001b[38;5;241m.\u001b[39mget_logdir(): \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_writer}\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpurge_step \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/RNARepLearn/lib/python3.10/site-packages/torch/utils/tensorboard/writer.py:76\u001b[0m, in \u001b[0;36mFileWriter.__init__\u001b[0;34m(self, log_dir, max_queue, flush_secs, filename_suffix)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# Sometimes PosixPath is passed in and we need to coerce it to\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# a string in all cases\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# TODO: See if we can remove this in the future if we are\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# actually the ones passing in a PosixPath\u001b[39;00m\n\u001b[1;32m     75\u001b[0m log_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(log_dir)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent_writer \u001b[38;5;241m=\u001b[39m \u001b[43mEventFileWriter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_queue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflush_secs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename_suffix\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/RNARepLearn/lib/python3.10/site-packages/tensorboard/summary/writer/event_file_writer.py:72\u001b[0m, in \u001b[0;36mEventFileWriter.__init__\u001b[0;34m(self, logdir, max_queue_size, flush_secs, filename_suffix)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a `EventFileWriter` and an event file to write to.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03mOn construction the summary writer creates a new event file in `logdir`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;124;03m    pending events and summaries to disk.\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logdir \u001b[38;5;241m=\u001b[39m logdir\n\u001b[0;32m---> 72\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mmakedirs(logdir)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file_name \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     74\u001b[0m     os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m     75\u001b[0m         logdir,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;241m+\u001b[39m filename_suffix\n\u001b[1;32m     85\u001b[0m )  \u001b[38;5;66;03m# noqa E128\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_general_file_writer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mGFile(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file_name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/RNARepLearn/lib/python3.10/site-packages/tensorboard/lazy.py:65\u001b[0m, in \u001b[0;36mlazy_load.<locals>.wrapper.<locals>.LazyModule.__getattr__\u001b[0;34m(self, attr_name)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr_name):\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[43mload_once\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m, attr_name)\n",
      "File \u001b[0;32m~/miniconda3/envs/RNARepLearn/lib/python3.10/site-packages/tensorboard/lazy.py:97\u001b[0m, in \u001b[0;36m_memoize.<locals>.wrapper\u001b[0;34m(arg)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m lock:\n\u001b[1;32m     96\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m cache\u001b[38;5;241m.\u001b[39mget(arg, nothing) \u001b[38;5;129;01mis\u001b[39;00m nothing:\n\u001b[0;32m---> 97\u001b[0m             cache[arg] \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cache[arg]\n",
      "File \u001b[0;32m~/miniconda3/envs/RNARepLearn/lib/python3.10/site-packages/tensorboard/lazy.py:50\u001b[0m, in \u001b[0;36mlazy_load.<locals>.wrapper.<locals>.load_once\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     48\u001b[0m load_once\u001b[38;5;241m.\u001b[39mloading \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 50\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mload_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m     load_once\u001b[38;5;241m.\u001b[39mloading \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/RNARepLearn/lib/python3.10/site-packages/tensorboard/compat/__init__.py:45\u001b[0m, in \u001b[0;36mtf\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 45\u001b[0m         \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tensorflow\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/RNARepLearn/lib/python3.10/site-packages/tensorflow/__init__.py:37\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_typing\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyLoader \u001b[38;5;28;01mas\u001b[39;00m _LazyLoader\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/RNARepLearn/lib/python3.10/site-packages/tensorflow/python/__init__.py:36\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtraceback\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# We aim to keep this file minimal and ideally remove completely.\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# If you are adding a new file with @tf_export decorators,\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# import it in modules_with_exports.py instead.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# go/tf-wildcard-import\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m context\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Bring in subpackages.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/RNARepLearn/lib/python3.10/site-packages/tensorflow/python/pywrap_tensorflow.py:62\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# pylint: disable=wildcard-import,g-import-not-at-top,line-too-long,undefined-variable\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 62\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pywrap_tensorflow_internal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# This try catch logic is because there is no bazel equivalent for py_extension.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Externally in opensource we must enable exceptions to load the shared object\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# by exposing the PyInit symbols with pybind. This error will only be\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# caught internally or if someone changes the name of the target _pywrap_tensorflow_internal.\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# This logic is used in other internal projects using py_extension.\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training = MaskedTraining(model, 1, 15, None, print_out=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "026ee8e8-3ed2-49d6-84df-566720500544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training running on device: cpu\n",
      "[Epoch    1/   1] [Batch   10/  11] Loss:  9.76e+00 Nucleotide-Loss:  1.39e+00 Edge-Loss:  8.38e+00  Memory    0\n",
      "[Epoch    1/   1] Epoch-Loss:  9.76e+00 Epoch-Loss Val:  9.79e+00 Nucleotide-Loss Val:  1.39e+00 Edge-Loss Val:  8.41e+00  Memory    0\n"
     ]
    }
   ],
   "source": [
    "training.run(train, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3221d624-8939-46e3-8846-205d91596f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0e9d8a-0b70-4bde-8b6e-6f183b8b734b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
