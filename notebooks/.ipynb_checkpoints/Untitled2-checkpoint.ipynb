{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c857e57-8f50-491e-9979-2f478d86e6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/icb/vnicolas.goedert/miniconda3/envs/RFAM/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fde15794-e4d9-43d1-87dd-c6f47579d4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete\n",
      "7969\n",
      "996\n",
      "997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "rfam_dir = \"../rfam/data/raw/processed/release-14.8\"\n",
    "rfams = [\"RF00001\",\"RF00174\",\"RF00169\",\"RF00050\"]\n",
    "\n",
    "from RNARepLearn.datasets import CombinedRfamDataset, SingleRfamDataset\n",
    "#dataset = CombinedRfamDataset(rfam_dir, rfams, \"Under300\", 15, 300)\n",
    "dataset = CombinedRfamDataset(rfam_dir, [\"RF00001\",\"RF00005\"], \"RF00001_RF00005\")\n",
    "\n",
    "from RNARepLearn.utils import train_val_test_loaders\n",
    "\n",
    "train_loader, val_loader, test_loader = train_val_test_loaders(dataset, 0.8, 0.1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e51fdec-0567-4029-9d90-ba15dca23f02",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(train_loader))\n\u001b[1;32m      3\u001b[0m layer \u001b[38;5;241m=\u001b[39m RPINetGNNLayer(\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m32\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/RFAM/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/RFAM/lib/python3.10/site-packages/RNARepLearn/layers.py:35\u001b[0m, in \u001b[0;36mRPINetGNNLayer.forward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x, edge_index, edge_weight):\n\u001b[1;32m     33\u001b[0m     lin_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin(x)\n\u001b[0;32m---> 35\u001b[0m     batched_x, fake_nodes_mask \u001b[38;5;241m=\u001b[39m to_dense_batch(x, \u001b[43mbatch\u001b[49m\u001b[38;5;241m.\u001b[39mbatch)\n\u001b[1;32m     36\u001b[0m     conv_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv(torch\u001b[38;5;241m.\u001b[39mtranspose(batched_x, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m     37\u001b[0m     conv_x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtranspose(conv_x, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)[fake_nodes_mask]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'batch' is not defined"
     ]
    }
   ],
   "source": [
    "from RNARepLearn.layers import RPINetGNNLayer\n",
    "batch = next(iter(train_loader))\n",
    "layer = RPINetGNNLayer(4,32)\n",
    "layer(batch.x, batch.edge_index, batch.batch, batch.edge_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43ef40b1-0171-496f-a8fa-9b186b7a812a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(\"runs/RF00001_RF00005_RPINet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fcef9ed-0b72-4587-afaa-4ddb840b949a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from RNARepLearn.modules import LinearEmbedding, RPINetEncoder, AttentionDecoder\n",
    "layers = []\n",
    "layers.append(LinearEmbedding(4, 32))\n",
    "layers.append(RPINetEncoder(32, 32, 3))\n",
    "layers.append(AttentionDecoder(32, 4))\n",
    "model = torch.nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f448cf9d-ad09-46ae-b1bb-e25d395e7c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from RNARepLearn.train import MaskedTraining\n",
    "training = MaskedTraining(model, 10, 15, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf5083fa-ddc9-4de8-9d53-b5a2d20be8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch    1/  10] [Batch    1/ 250] Loss:  8.83e+00 Nucleotide-Loss:  1.39e+00 Edge-Loss:  7.44e+00\n",
      "[Epoch    1/  10] [Batch   11/ 250] Loss:  7.92e+00 Nucleotide-Loss:  1.38e+00 Edge-Loss:  6.54e+00\n",
      "[Epoch    1/  10] [Batch   21/ 250] Loss:  7.64e+00 Nucleotide-Loss:  1.38e+00 Edge-Loss:  6.26e+00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtraining\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/RFAM/lib/python3.10/site-packages/RNARepLearn/train.py:61\u001b[0m, in \u001b[0;36mMaskedTraining.run\u001b[0;34m(self, data_loader, val_loader)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m val_loader:\n\u001b[1;32m     60\u001b[0m     true_x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mclone(batch\u001b[38;5;241m.\u001b[39mx)\n\u001b[0;32m---> 61\u001b[0m     nuc_mask, edge_mask \u001b[38;5;241m=\u001b[39m \u001b[43mmask_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     batch\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/miniconda3/envs/RFAM/lib/python3.10/site-packages/RNARepLearn/utils.py:8\u001b[0m, in \u001b[0;36mmask_batch\u001b[0;34m(batch, percentage)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmask_batch\u001b[39m(batch, percentage):\n\u001b[0;32m----> 8\u001b[0m     mask \u001b[38;5;241m=\u001b[39m [random\u001b[38;5;241m.\u001b[39mrandrange(\u001b[38;5;241m100\u001b[39m) \u001b[38;5;241m<\u001b[39m percentage \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(batch\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])]\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# mask nodes\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     batch\u001b[38;5;241m.\u001b[39mx[mask] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m0.0\u001b[39m,\u001b[38;5;241m0.0\u001b[39m,\u001b[38;5;241m0.0\u001b[39m,\u001b[38;5;241m0.0\u001b[39m],dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat64)\n",
      "File \u001b[0;32m~/miniconda3/envs/RFAM/lib/python3.10/site-packages/RNARepLearn/utils.py:8\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmask_batch\u001b[39m(batch, percentage):\n\u001b[0;32m----> 8\u001b[0m     mask \u001b[38;5;241m=\u001b[39m [\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandrange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m<\u001b[39m percentage \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(batch\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])]\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# mask nodes\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     batch\u001b[38;5;241m.\u001b[39mx[mask] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m0.0\u001b[39m,\u001b[38;5;241m0.0\u001b[39m,\u001b[38;5;241m0.0\u001b[39m,\u001b[38;5;241m0.0\u001b[39m],dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat64)\n",
      "File \u001b[0;32m~/miniconda3/envs/RFAM/lib/python3.10/random.py:303\u001b[0m, in \u001b[0;36mRandom.randrange\u001b[0;34m(self, start, stop, step)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;66;03m# This code is a bit messy to make it fast for the\u001b[39;00m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;66;03m# common case while still doing adequate error checking.\u001b[39;00m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 303\u001b[0m     istart \u001b[38;5;241m=\u001b[39m \u001b[43m_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    305\u001b[0m     istart \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(start)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training.run(train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765ece80-aab6-45c7-9482-3e1c7c4e2116",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3b19fbe3-7ffd-43f0-a4c2-617ec9325071",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import LSTM, Conv1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5b88fe9d-c435-4ab1-82ae-8c1523d7b402",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = Conv1d(4, 32, 3, padding='same').double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "93581e55-84b4-4bef-80bd-ea7674770810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(x=[3085, 4], edge_index=[2, 116681], edge_weight=[116681], rfam=[32], ID=[32], batch=[3085], ptr=[33])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "60551186-b4ae-4a4a-aa3d-55f8fe1aba65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import to_dense_batch\n",
    "batch, mask = to_dense_batch(batch.x, batch.batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "aa9e2418-d367-4940-9dc1-366844548b94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 167, 4])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b05674e9-fa72-472c-9bd5-dfb0f31d58b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3085, 32])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.transpose(conv(torch.transpose(batch.double(), 1, 2)), 1, 2)[mask].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b1ab1cfd-87cc-42f5-bd1a-815d5fb8ce07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([123, 32])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Data, Batch\n",
    "dat_list=[]\n",
    "for x in torch.transpose(conv(torch.transpose(batch.double(), 1, 2)), 1, 2):\n",
    "    print(x.shape)\n",
    "    dat = Data(x=x)\n",
    "    dat_list.append(dat)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "012c327d-1e47-451b-9c0e-d468409c38a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c8d62e8d-2062-4c1d-b3e5-b20c47f2f9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = Batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e1a9af7f-478b-4a06-b616-5c2c16eb9fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataDataBatch(x=[4000, 32], batch=[4000], ptr=[33])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.from_data_list(dat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d679daf-ef7d-4981-81a6-38b8d640f66b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RFAM",
   "language": "python",
   "name": "rfam"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
