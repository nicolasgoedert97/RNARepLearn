{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbc82efd-653e-4b80-81bd-4b703c657b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/icb/vnicolas.goedert/miniconda3/envs/RFAM/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch_geometric\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d7ef16a-d061-404f-8cb3-36f3c24399b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfam_dir = \"../RNARepLearn/rfam/data/raw/processed/release-14.8\"\n",
    "rfam_id = \"RF00008\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "ea11fcbb-d568-40e0-8051-316427eb525b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleMaskedRfamDataset(torch_geometric.data.Dataset): \n",
    "    \n",
    "    ###Contains single RFAM family with masked sequence\n",
    "    \n",
    "    def __init__(self, rfam_dir, rfam_id, transform=None, pre_transform=None, pre_filter=None):\n",
    "        self.dir = rfam_dir\n",
    "        self.id = rfam_id\n",
    "        super().__init__(rfam_dir, transform, pre_transform, pre_filter)\n",
    "    \n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return(os.path.join(self.dir, self.id, self.id+\".npy\"))\n",
    "    \n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return os.listdir(os.path.join(self.dir,self.id,\"pt\"))\n",
    "    \n",
    "    \n",
    "    def one_hot_encode(self, seq):\n",
    "        nuc_d = {0:[1.0,0.0,0.0,0.0],\n",
    "                 1:[0.0,1.0,0.0,0.0],\n",
    "                 2:[0.0,0.0,1.0,0.0],\n",
    "                 3:[0.0,0.0,0.0,1.0]}\n",
    "        vec=np.array([nuc_d[x] for x in seq])\n",
    "        return vec\n",
    "    \n",
    "    def generate_edges(self,seq_len,bpp):\n",
    "        X = np.zeros((seq_len,seq_len))\n",
    "        X[np.triu_indices(X.shape[0], k = 1)] = bpp\n",
    "        X = X+X.T\n",
    "        df = pd.DataFrame(X)\n",
    "        np.fill_diagonal(df.values, np.nan)\n",
    "        adf = df.stack().reset_index()\n",
    "        adf = adf.rename(columns={\"level_0\":\"A\",\"level_1\":\"B\",0:\"weight\"})\n",
    "        return (adf.loc[adf[\"weight\"]!=0.0])[[\"A\",\"B\"]].to_numpy()\n",
    "    \n",
    "    \n",
    "    def process(self):\n",
    "        if not os.path.exists(os.path.join(self.dir, self.id,\"pt\")):\n",
    "            os.makedirs(os.path.join(self.dir, self.id,\"pt\"))\n",
    "        with open(self.raw_file_names,\"rb\") as f:\n",
    "            n = 0\n",
    "            while True:\n",
    "                try: \n",
    "                    array = np.load(f, allow_pickle=True)\n",
    "                    \n",
    "                    \n",
    "                    ## seq (node features one-hot encoded sequence) and classes (node classes) are essentially the same right now. Just for proof of concept\n",
    "                    ## TODO replace with significant features (e.g. position/order in sequence)\n",
    "                    \n",
    "                    seq = torch.tensor(self.one_hot_encode(array.item()['seq_int']))\n",
    "                    classes = torch.tensor(array.item()['seq_int'])\n",
    "                    \n",
    "                    struc = torch.tensor(self.generate_edges(len(array.item()['seq_int']),array.item()['bpp']))\n",
    "                    rfam_id = array.item()['id'].replace(\"/\",\"_\")\n",
    "                    torch.save({\"seq\":seq, \"edges\":struc, \"rfam\":array.item()['rfam_id'],\"classes\":classes ,\"id\":rfam_id}, os.path.join(self.dir, self.id,\"pt\",rfam_id+\".pt\"))\n",
    "                    \n",
    "                except pickle.UnpicklingError:\n",
    "                    \n",
    "                    break\n",
    "            f.close()\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.processed_file_names)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        self.processed_file_names[index]\n",
    "        data = torch.load(os.path.join(self.dir,self.id,\"pt\",self.processed_file_names[index]))\n",
    "        return torch_geometric.data.Data(x=data[\"seq\"],edge_index=data[\"edges\"].t().contiguous(),y=data[\"classes\"],rfam=data[\"rfam\"],ID=data[\"id\"])\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "aa0a0e21-a0bf-4b20-a509-202d355cdad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "rfam_dataset = SingleMaskedRfamDataset(rfam_dir,rfam_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "e887b2b5-dbea-42f5-9a8c-3fdd089a7251",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(rfam_dataset.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, 4)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "0a039dea-0e68-443a-ac0d-58c17afde13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up mask\n",
    "import random\n",
    "train_mask = torch.tensor([random.randrange(100) < 30 for i in range(rfam_dataset[0].num_nodes)])\n",
    "test_mask = torch.tensor([random.randrange(100) < 30 for i in range(rfam_dataset[0].num_nodes)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "a28d4ccb-4112-48c6-b79c-d5d459efd99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN().to(device)\n",
    "model = model.double()\n",
    "data = rfam_dataset[0].to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[train_mask], data[\"y\"][train_mask].long())\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "36c21918-7255-4a78-a1ee-2c6bad1c94b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "pred = model(data).argmax(dim=1)\n",
    "correct = (pred[test_mask] == data.y[test_mask]).sum()\n",
    "acc = int(correct) / int(test_mask.sum())\n",
    "print(f'Accuracy: {acc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RFAM",
   "language": "python",
   "name": "rfam"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
